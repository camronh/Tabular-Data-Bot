{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The first step is to get the data we will be working with from Kaggle.\n",
    "\n",
    "Gonna use this one\n",
    "\n",
    "https://www.kaggle.com/datasets/alanvourch/tmdb-movies-daily-updates\n",
    "\n",
    "it has a ton of data in it, about 240mb. We can do a lot with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install pandas openai python-dotenv chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv in ../raw/TMDB_all_movies.csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../raw/TMDB_all_movies.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the columns of the dataframe\n",
    "print(df.columns)\n",
    "# Print the dtypes of the dataframe\n",
    "print(df.dtypes)\n",
    "# Print the info of the dataframe\n",
    "print(df.info())\n",
    "# Print the description of the dataframe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a row\n",
    "print(df.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date and find first and last date\n",
    "df = df.sort_values(by='release_date', ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all possible options in status column\n",
    "df['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "released = df[df['status'] == 'Released']\n",
    "print(released.shape)\n",
    "released.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows where the release_date is before 2025\n",
    "before_2025 = released[released['release_date'] < '2025-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_1950 = before_2025[before_2025['release_date'] > '1950-01-01']\n",
    "\n",
    "print(after_1950.shape)\n",
    "after_1950.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies with a vote count of more than 0\n",
    "voted_on = after_1950[after_1950['vote_count'] > 0]\n",
    "print(voted_on.shape)\n",
    "voted_on.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by vote count\n",
    "voted_on = voted_on.sort_values(by='vote_count', ascending=False)\n",
    "voted_on.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_by_vote_count = voted_on.head(150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "Okay now we need to get the embeddings\n",
    "\n",
    "We are going to embed just the title and overview for now using openai embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = top_by_vote_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all of the titles their overviews\n",
    "titles = df['title'].tolist()\n",
    "overviews = df['overview'].tolist()\n",
    "\n",
    "titles_and_overviews = [f\"{title} {overview}\" for title, overview in zip(titles, overviews)]\n",
    "\n",
    "print(titles_and_overviews[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "from tqdm.notebook import tqdm\n",
    "from math import ceil\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chunkify(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "chunk_size = 2048\n",
    "model_name = \"text-embedding-3-large\"  # Ensure this is the correct model name\n",
    "\n",
    "# Initialize list to store embeddings\n",
    "all_embeddings = []\n",
    "\n",
    "# Calculate total number of chunks\n",
    "total_chunks = ceil(len(titles_and_overviews) / chunk_size)\n",
    "\n",
    "# Process each chunk\n",
    "for chunk in chunkify(titles_and_overviews, chunk_size):\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=chunk,\n",
    "            model=model_name\n",
    "        )\n",
    "        # Extract embeddings from the response and append to the list\n",
    "        embeddings = [embedding.embedding for embedding in response.data]\n",
    "        all_embeddings.extend(embeddings)\n",
    "        print(f\"Processed {len(all_embeddings)} embeddings out of {len(titles_and_overviews)}\")\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        # Optionally, implement retry logic or handle the error as needed\n",
    "        raise e\n",
    "\n",
    "# Verify the number of embeddings matches the number of documents\n",
    "assert len(all_embeddings) == len(\n",
    "    titles_and_overviews), \"Mismatch between embeddings and documents.\"\n",
    "\n",
    "# Now, all_embeddings[i] corresponds to titles_and_overviews[i]\n",
    "print(\"All embeddings generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy df and add the embeddings\n",
    "df_with_embeddings = df.copy()\n",
    "df_with_embeddings['embedding'] = all_embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the id column and the index column and replace them with i in order of vote count\n",
    "ided_df = df_with_embeddings.reset_index().drop(columns=['id'])\n",
    "ided_df = ided_df.drop(columns=['index'])\n",
    "ided_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the dataframe\n",
    "ided_df.to_pickle('../raw/df_with_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you're using a chroma db client for semantic search\n",
    "from chromadb import Client\n",
    "\n",
    "\n",
    "def get_embeddings(inputs: list[str], model_name: str = \"text-embedding-3-large\"):\n",
    "    response = client.embeddings.create(\n",
    "        input=inputs,\n",
    "        model=model_name\n",
    "    )\n",
    "    return [embedding.embedding for embedding in response.data]\n",
    "\n",
    "\n",
    "def load_df(file_path: str = '../raw/df_with_embeddings.pkl'):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "\n",
    "class MovieData:\n",
    "    def __init__(self, movies_df: pd.DataFrame):\n",
    "        self.df = movies_df\n",
    "        batch_size = 41666\n",
    "\n",
    "        print(\"Loading vector db\")\n",
    "        self.db_client = Client()  # Assuming chromadb client initialization\n",
    "\n",
    "        # If collection exists, use it\n",
    "        try:\n",
    "            self.collection = self.db_client.get_collection(name=\"movies\")\n",
    "            entries = self.collection.count()\n",
    "            if entries != len(self.df):\n",
    "                print(\"Collection does not match the number of movies\")\n",
    "                raise ValueError(\n",
    "                    \"Collection does not match the number of movies\")\n",
    "        except:\n",
    "            self.collection = self.db_client.get_or_create_collection(\n",
    "                name=\"movies\")\n",
    "\n",
    "            ids = self.df.index.tolist()\n",
    "            id_strings = [str(id) for id in ids]\n",
    "            embeddings = self.df['embedding'].tolist()\n",
    "\n",
    "            for i in range(0, len(ids), batch_size):\n",
    "                print(f\"Processing batch {i} of {len(ids)}\")\n",
    "                batch_ids = id_strings[i:i + batch_size]\n",
    "                batch_embeddings = embeddings[i:i + batch_size]\n",
    "                self.collection.upsert(\n",
    "                    ids=batch_ids, embeddings=batch_embeddings)\n",
    "\n",
    "    def semantic_search(self, query: str, k: int = 10):\n",
    "        response = client.embeddings.create(\n",
    "            input=query,\n",
    "            model=model_name\n",
    "        )\n",
    "        query_embedding = response.data[0].embedding\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding], n_results=k)\n",
    "        ids: list[str] = results['ids'][0]\n",
    "        # df from the ids\n",
    "        ids = [int(i) for i in ids]\n",
    "\n",
    "        results_df = self.df.loc[ids]\n",
    "        results_df[\"distance\"] = results['distances'][0]\n",
    "        return results_df\n",
    "\n",
    "\n",
    "# movie_data = MovieData(ided_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_data.semantic_search(\"Ghosts of a relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = load_df()\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 1500\n",
    "top_1500 = full_df.head(50000)\n",
    "top_1500.to_pickle('../raw/top_50000.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top: pd.DataFrame = pd.read_pickle('../raw/top_50000.pkl')\n",
    "top.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Precompute norms for the movie embeddings to speed up cosine similarity\n",
    "# self.df['embedding'] = self.df['embedding'].apply(np.array)\n",
    "# self.df['embedding_norm'] = self.df['embedding'].apply(np.linalg.norm)\n",
    "import numpy as np\n",
    "\n",
    "top['embedding'] = top['embedding'].apply(np.array)\n",
    "top['embedding_norm'] = top['embedding'].apply(np.linalg.norm)\n",
    "\n",
    "top.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top.to_pickle('../raw/top_50000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
